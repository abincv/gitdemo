{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d90d7e0",
   "metadata": {},
   "source": [
    "#### Numpy Assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f40e746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rowise: \n",
      "\n",
      " [[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]] \n",
      "\n",
      "\n",
      "coloumnwise: \n",
      "\n",
      " [[1. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#1.How to concatenate two numpy arrays column-wise and row-wise?\n",
    "\n",
    "import numpy as np\n",
    "arr1 = np.ones((4,4))\n",
    "arr2 = np.zeros((4,4))\n",
    "\n",
    "#rowwise\n",
    "print(\"rowise: \\n\\n {} \\n\\n\".format(np.concatenate((arr1,arr2))))\n",
    "\n",
    "#coloumnwise\n",
    "print(\"coloumnwise: \\n\\n {}\".format(np.concatenate((arr1,arr2),axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0df9d366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1653201 , 0.14283478, 0.51027799],\n",
       "       [0.27183159, 0.64588057, 0.8751932 ],\n",
       "       [0.54764515, 0.63499353, 0.14449935],\n",
       "       [0.58633679, 0.42643628, 0.91518673]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.Consider the random number generation functions in NumPy generate a set of random numbers using the function rand\n",
    "\n",
    "np.random.rand(4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5875e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[8, 9],\n",
       "        [5, 8],\n",
       "        [6, 6]],\n",
       "\n",
       "       [[5, 7],\n",
       "        [9, 5],\n",
       "        [5, 8]],\n",
       "\n",
       "       [[8, 5],\n",
       "        [7, 6],\n",
       "        [9, 9]],\n",
       "\n",
       "       [[9, 6],\n",
       "        [7, 5],\n",
       "        [9, 6]],\n",
       "\n",
       "       [[9, 8],\n",
       "        [8, 7],\n",
       "        [5, 7]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3. Create a 3D array of shape 5x3x2 to contain random decimal numbers between 5 and 10\n",
    "\n",
    "np.random.randint(5,10,size=(5,3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aac91796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([628, 815, 823, 314, 155])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4.Create a utility function to generate random arrays using def random_array() takes number of elements as one \n",
    "#  of the argument, and randint() from random library. \n",
    "#Note: Do not use numpy function in this.\n",
    "\n",
    "def random_array(n):\n",
    "    return np.random.randint(999,size=n)\n",
    "    \n",
    "random_array(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f062c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median using defied method: 8.5\n",
      "Median using NumPy: 8.5\n"
     ]
    }
   ],
   "source": [
    "# 5.Create and Compute median using both Naive method using python only and Numpy function np.median()\n",
    "\n",
    "def median_array(arr):\n",
    "    arr.sort()\n",
    "    size=len(arr)\n",
    "    mid=int(size/2)\n",
    "    if(size%2==0):\n",
    "        return ((arr[mid]+arr[mid-1])/2)\n",
    "    \n",
    "    else:\n",
    "        return (arr[mid])\n",
    "    \n",
    "\n",
    "temp=[1,2,10,7,5,4,88,55,0,77,54,33]   \n",
    "print(\"Median using defied method: {}\".format(median_array(temp)))\n",
    "print(\"Median using NumPy: {}\".format(np.median(temp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cc18e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean : 3.5\n",
      "Variance : 2.9166666666666665 \n"
     ]
    }
   ],
   "source": [
    "#6.Create naive function to compute variance function, mean function using only python.\n",
    "\n",
    "def mean(arr):\n",
    "    return sum(arr)/len(arr)\n",
    "  \n",
    "def variance(arr): \n",
    "    avg=mean(arr)\n",
    "    return sum(list(map(lambda x : (x-avg)**2 , arr)))/len(arr)\n",
    "    \n",
    "\n",
    "temp = [1,2,3,4,5,6]\n",
    "print(\"Mean : {}\" .format(mean(temp)))\n",
    "print(\"Variance : {} \" .format(variance(temp)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f33d571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2 3 4]\n",
      " [5 6 7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "#7 Convert a 1D array to a 2D array with 2 rows.\n",
    "#    e.g. \n",
    "#    Input Array: ([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "#    Output: [[0, 1, 2, 3, 4],\n",
    "#     [5, 6, 7, 8, 9]]\n",
    "\n",
    "arr=np.array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "if(len(arr)%2==0):\n",
    "    print(arr.reshape(2,int(len(arr)/2)))\n",
    "else:\n",
    "    print(\"cannot split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6aba7395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[44, 34, 45, 42],\n",
       "       [40, 43, 40, 49],\n",
       "       [43, 48, 48, 39],\n",
       "       [46, 34, 46, 32],\n",
       "       [10,  6,  1, 10],\n",
       "       [ 8,  5, 17, 12],\n",
       "       [ 0, 17,  3,  4],\n",
       "       [ 1,  1, 14, 19]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8.How to stack two arrays vertically? Stack arrays A and B vertically?\n",
    "\n",
    "A = np.random.randint(30,50,size=(4,4))\n",
    "B = np.random.randint(20,size=(4,4))\n",
    "np.vstack((A,B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fab1830d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 6, 9])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#9.Create a function using numpy to get the common items between two python numpy arrays?\n",
    "\n",
    "A = np.random.randint(10,size=10)\n",
    "B = np.random.randint(20,size=20)\n",
    "np.intersect1d(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "899d76f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 2],\n",
       "       [0, 3],\n",
       "       [1, 2],\n",
       "       [1, 4]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10.Create a python function to get the positions where elements of two arrays match using Numpy function?\n",
    "\n",
    "arr1 = np.array([[1,20,30,2,3],[4,3,7,5,6]])\n",
    "arr2 = np.array([[10,20,30,2,4],[5,6,7,8,6]])\n",
    "np.argwhere(arr1==arr2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abb2a1fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.21914615, 8.54115214, 9.45586231],\n",
       "       [6.19400184, 8.0226404 , 5.20465437],\n",
       "       [7.10448445, 7.73621865, 9.3330191 ],\n",
       "       [8.12214874, 8.38409485, 5.5413374 ],\n",
       "       [6.62202089, 5.1863742 , 5.32861913]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#11. How to create a 2D array containing random floats between 5 and 10?\n",
    "\n",
    "(10-5)*np.random.ranf((5,3))+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "447beb84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'setosa', 'setosa', 'setosa', 'setosa',\n",
       "       'setosa', 'setosa', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'versicolor',\n",
       "       'versicolor', 'versicolor', 'versicolor', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica', 'virginica', 'virginica',\n",
       "       'virginica', 'virginica', 'virginica'], dtype='<U12')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#12. Extract the text column species from the 1D iris imported using following url np.genfromtxt()\n",
    "# https://raw.githubusercontent.com/ammishra08/MachineLearning/master/Datasets/iris.csv\n",
    "\n",
    "iris_dataset=np.genfromtxt(\"https://raw.githubusercontent.com/ammishra08/MachineLearning/master/Datasets/iris.csv\",dtype=\"str\",delimiter=\",\")\n",
    "\n",
    "iris_dataset[1:,4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdf0a57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n"
     ]
    }
   ],
   "source": [
    "#13. How to Convert the 1D iris to 2D array iris_2d by omitting the species column and dropping first row?\n",
    "\n",
    "\n",
    "iris_dataset=np.genfromtxt(\"https://raw.githubusercontent.com/ammishra08/MachineLearning/master/Datasets/iris.csv\",delimiter=\",\",usecols=(0,1,2,3),skip_header=1)\n",
    "print(iris_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b40d6fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.84333333, 3.05733333, 3.758     , 1.19933333])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#14. How to compute the mean, median, standard deviation of a numpy array on the same iris dataset?\n",
    "\n",
    "iris_dataset.mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33be3643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82530129, 0.43441097, 1.75940407, 0.75969263])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dataset.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "999b4b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.8 , 3.  , 4.35, 1.3 ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(iris_dataset,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b69c5cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.   337.   118.   ...   9.65   1.     0.92]\n",
      " [  2.   324.   107.   ...   8.87   1.     0.76]\n",
      " [  3.   316.   104.   ...   8.     1.     0.72]\n",
      " ...\n",
      " [498.   330.   120.   ...   9.56   1.     0.93]\n",
      " [499.   312.   103.   ...   8.43   0.     0.73]\n",
      " [500.   327.   113.   ...   9.04   0.     0.84]]\n"
     ]
    }
   ],
   "source": [
    "#15. How to scale an array so the values range exactly between 0 and 1 using Admission.csv?\n",
    "#    https://raw.githubusercontent.com/ammishra08/MachineLearning/master/Datasets/Admission.csv\n",
    "#    Change all the values in the range of 0-1.\n",
    "\n",
    "admission_dataset=np.loadtxt(\"Admission.csv\",delimiter=\",\",skiprows=1)\n",
    "print(admission_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75457045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.94      , 0.92857143, ..., 0.91346154, 1.        ,\n",
       "        0.92063492],\n",
       "       [0.00200401, 0.68      , 0.53571429, ..., 0.66346154, 1.        ,\n",
       "        0.66666667],\n",
       "       [0.00400802, 0.52      , 0.42857143, ..., 0.38461538, 1.        ,\n",
       "        0.6031746 ],\n",
       "       ...,\n",
       "       [0.99599198, 0.8       , 1.        , ..., 0.88461538, 1.        ,\n",
       "        0.93650794],\n",
       "       [0.99799599, 0.44      , 0.39285714, ..., 0.5224359 , 0.        ,\n",
       "        0.61904762],\n",
       "       [1.        , 0.74      , 0.75      , ..., 0.71794872, 0.        ,\n",
       "        0.79365079]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(admission_dataset-np.min(admission_dataset,axis=0))/np.ptp(admission_dataset,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b98da5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2a1b727",
   "metadata": {},
   "outputs": [],
   "source": [
    "#16. Compute and Find the number and position of missing values in iris data’s sepal length column.\n",
    "#    (And few missing values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "639c51e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "position:\n",
      "[[  0]\n",
      " [  5]\n",
      " [ 10]\n",
      " [ 14]\n",
      " [ 15]\n",
      " [ 16]\n",
      " [ 17]\n",
      " [ 18]\n",
      " [ 19]\n",
      " [ 20]\n",
      " [ 21]\n",
      " [ 23]\n",
      " [ 27]\n",
      " [ 28]\n",
      " [ 31]\n",
      " [ 32]\n",
      " [ 33]\n",
      " [ 36]\n",
      " [ 39]\n",
      " [ 44]\n",
      " [ 46]\n",
      " [ 48]\n",
      " [ 50]\n",
      " [ 51]\n",
      " [ 52]\n",
      " [ 53]\n",
      " [ 54]\n",
      " [ 55]\n",
      " [ 56]\n",
      " [ 58]\n",
      " [ 59]\n",
      " [ 61]\n",
      " [ 62]\n",
      " [ 63]\n",
      " [ 64]\n",
      " [ 65]\n",
      " [ 66]\n",
      " [ 67]\n",
      " [ 68]\n",
      " [ 69]\n",
      " [ 70]\n",
      " [ 71]\n",
      " [ 72]\n",
      " [ 73]\n",
      " [ 74]\n",
      " [ 75]\n",
      " [ 76]\n",
      " [ 77]\n",
      " [ 78]\n",
      " [ 79]\n",
      " [ 80]\n",
      " [ 81]\n",
      " [ 82]\n",
      " [ 83]\n",
      " [ 84]\n",
      " [ 85]\n",
      " [ 86]\n",
      " [ 87]\n",
      " [ 88]\n",
      " [ 89]\n",
      " [ 90]\n",
      " [ 91]\n",
      " [ 92]\n",
      " [ 94]\n",
      " [ 95]\n",
      " [ 96]\n",
      " [ 97]\n",
      " [ 98]\n",
      " [ 99]\n",
      " [100]\n",
      " [101]\n",
      " [102]\n",
      " [103]\n",
      " [104]\n",
      " [105]\n",
      " [107]\n",
      " [108]\n",
      " [109]\n",
      " [110]\n",
      " [111]\n",
      " [112]\n",
      " [113]\n",
      " [114]\n",
      " [115]\n",
      " [116]\n",
      " [117]\n",
      " [118]\n",
      " [119]\n",
      " [120]\n",
      " [121]\n",
      " [122]\n",
      " [123]\n",
      " [124]\n",
      " [125]\n",
      " [126]\n",
      " [127]\n",
      " [128]\n",
      " [129]\n",
      " [130]\n",
      " [131]\n",
      " [132]\n",
      " [133]\n",
      " [134]\n",
      " [135]\n",
      " [136]\n",
      " [137]\n",
      " [138]\n",
      " [139]\n",
      " [140]\n",
      " [141]\n",
      " [142]\n",
      " [143]\n",
      " [144]\n",
      " [145]\n",
      " [146]\n",
      " [147]\n",
      " [148]\n",
      " [149]] \n",
      " count:118 \n"
     ]
    }
   ],
   "source": [
    "iris_dataset_temp = np.where(iris_dataset>5,np.nan,iris_dataset)\n",
    "sepal_length_col= iris_dataset_temp[:,0]\n",
    "\n",
    "#sepal_length_col\n",
    "print(\"position:\\n{} \\n count:{} \".format(np.argwhere(np.isnan(sepal_length_col)),len((np.argwhere(np.isnan(sepal_length_col))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9779f41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1be0bf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#17. Drop rows that contain a missing value from a numpy array created by using iris dataset?\n",
    "#   Hint: There is no direct function for this hence, select the rows of Iris dataset that does not have any\n",
    "#   NaN value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "000f43b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [4.9, 2.5, 4.5, 1.7]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dataset_temp[~np.isnan(iris_dataset_temp).any(axis=1),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f99a91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2119df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#18. Sort the Admission dataset array based on TOEFL Score column and GRE Score. Use separate code for\n",
    "#    both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8b009cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[378.  , 290.  , 100.  , ...,   7.56,   0.  ,   0.47],\n",
       "       [118.  , 290.  , 104.  , ...,   7.46,   0.  ,   0.45],\n",
       "       [169.  , 293.  ,  97.  , ...,   7.8 ,   1.  ,   0.64],\n",
       "       ...,\n",
       "       [144.  , 340.  , 120.  , ...,   9.92,   1.  ,   0.97],\n",
       "       [385.  , 340.  , 113.  , ...,   9.74,   1.  ,   0.96],\n",
       "       [430.  , 340.  , 115.  , ...,   9.06,   1.  ,   0.95]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GRE score\n",
    "admission_dataset[admission_dataset[:, 1].argsort(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d8dacb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[369.  , 298.  ,  92.  , ...,   7.88,   0.  ,   0.51],\n",
       "       [ 29.  , 295.  ,  93.  , ...,   7.2 ,   0.  ,   0.46],\n",
       "       [ 80.  , 294.  ,  93.  , ...,   7.36,   0.  ,   0.46],\n",
       "       ...,\n",
       "       [298.  , 320.  , 120.  , ...,   9.11,   0.  ,   0.86],\n",
       "       [144.  , 340.  , 120.  , ...,   9.92,   1.  ,   0.97],\n",
       "       [498.  , 330.  , 120.  , ...,   9.56,   1.  ,   0.93]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TOEFL score\n",
    "np.set_printoptions(suppress=True)\n",
    "admission_dataset[admission_dataset[:, 2].argsort(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "290a2a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#19. Compute the Euclidean distance between two arrays using Numpy linalg?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd381689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.830951894845301\n"
     ]
    }
   ],
   "source": [
    "p1 = np.array((0, 1, 2))\n",
    "p2 = np.array((3, 4, 6))\n",
    "\n",
    "print(np.linalg.norm(p1-p2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1250742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0083124",
   "metadata": {},
   "outputs": [],
   "source": [
    "#20. Compute and Find the duplicate entries in the given Numpy array and mark them as True. \n",
    "#    Create 1-D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a67d9906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array:  [1, 2, 3, 4, 3, 2, 5, 7, 8]\n",
      "[1, 2, 3, 4, True, True, 5, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def duplicates(a):\n",
    "    uniques = np.unique(a)\n",
    "    result = []\n",
    "    for i in a:\n",
    "        if i not in uniques:\n",
    "            result.append(True)\n",
    "        else:\n",
    "            result.append(i)\n",
    "            uniques = np.delete(uniques, np.where(uniques == i))\n",
    "    return result\n",
    "\n",
    "\n",
    "arr=[1,2,3,4,3,2,5,7,8]\n",
    "print('Array: ', arr)\n",
    "print(duplicates(arr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282fa3f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "840f3747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#21. How to replace all missing values with 0, in a numpy array using Admission.csv and iris.csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4973b5cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3cb275fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [0. , 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [0. , 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [0. , 4. , 1.2, 0.2],\n",
       "       [0. , 4.4, 1.5, 0.4],\n",
       "       [0. , 3.9, 1.3, 0.4],\n",
       "       [0. , 3.5, 1.4, 0.3],\n",
       "       [0. , 3.8, 1.7, 0.3],\n",
       "       [0. , 3.8, 1.5, 0.3],\n",
       "       [0. , 3.4, 1.7, 0.2],\n",
       "       [0. , 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [0. , 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [0. , 3.5, 1.5, 0.2],\n",
       "       [0. , 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [0. , 3.4, 1.5, 0.4],\n",
       "       [0. , 4.1, 1.5, 0.1],\n",
       "       [0. , 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [0. , 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [0. , 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [0. , 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [0. , 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [0. , 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [0. , 3.2, 4.7, 1.4],\n",
       "       [0. , 3.2, 4.5, 1.5],\n",
       "       [0. , 3.1, 4.9, 1.5],\n",
       "       [0. , 2.3, 4. , 1.3],\n",
       "       [0. , 2.8, 4.6, 1.5],\n",
       "       [0. , 2.8, 4.5, 1.3],\n",
       "       [0. , 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [0. , 2.9, 4.6, 1.3],\n",
       "       [0. , 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [0. , 3. , 4.2, 1.5],\n",
       "       [0. , 2.2, 4. , 1. ],\n",
       "       [0. , 2.9, 4.7, 1.4],\n",
       "       [0. , 2.9, 3.6, 1.3],\n",
       "       [0. , 3.1, 4.4, 1.4],\n",
       "       [0. , 3. , 4.5, 1.5],\n",
       "       [0. , 2.7, 4.1, 1. ],\n",
       "       [0. , 2.2, 4.5, 1.5],\n",
       "       [0. , 2.5, 3.9, 1.1],\n",
       "       [0. , 3.2, 4.8, 1.8],\n",
       "       [0. , 2.8, 4. , 1.3],\n",
       "       [0. , 2.5, 4.9, 1.5],\n",
       "       [0. , 2.8, 4.7, 1.2],\n",
       "       [0. , 2.9, 4.3, 1.3],\n",
       "       [0. , 3. , 4.4, 1.4],\n",
       "       [0. , 2.8, 4.8, 1.4],\n",
       "       [0. , 3. , 5. , 1.7],\n",
       "       [0. , 2.9, 4.5, 1.5],\n",
       "       [0. , 2.6, 3.5, 1. ],\n",
       "       [0. , 2.4, 3.8, 1.1],\n",
       "       [0. , 2.4, 3.7, 1. ],\n",
       "       [0. , 2.7, 3.9, 1.2],\n",
       "       [0. , 2.7, 0. , 1.6],\n",
       "       [0. , 3. , 4.5, 1.5],\n",
       "       [0. , 3.4, 4.5, 1.6],\n",
       "       [0. , 3.1, 4.7, 1.5],\n",
       "       [0. , 2.3, 4.4, 1.3],\n",
       "       [0. , 3. , 4.1, 1.3],\n",
       "       [0. , 2.5, 4. , 1.3],\n",
       "       [0. , 2.6, 4.4, 1.2],\n",
       "       [0. , 3. , 4.6, 1.4],\n",
       "       [0. , 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [0. , 2.7, 4.2, 1.3],\n",
       "       [0. , 3. , 4.2, 1.2],\n",
       "       [0. , 2.9, 4.2, 1.3],\n",
       "       [0. , 2.9, 4.3, 1.3],\n",
       "       [0. , 2.5, 3. , 1.1],\n",
       "       [0. , 2.8, 4.1, 1.3],\n",
       "       [0. , 3.3, 0. , 2.5],\n",
       "       [0. , 2.7, 0. , 1.9],\n",
       "       [0. , 3. , 0. , 2.1],\n",
       "       [0. , 2.9, 0. , 1.8],\n",
       "       [0. , 3. , 0. , 2.2],\n",
       "       [0. , 3. , 0. , 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [0. , 2.9, 0. , 1.8],\n",
       "       [0. , 2.5, 0. , 1.8],\n",
       "       [0. , 3.6, 0. , 2.5],\n",
       "       [0. , 3.2, 0. , 2. ],\n",
       "       [0. , 2.7, 0. , 1.9],\n",
       "       [0. , 3. , 0. , 2.1],\n",
       "       [0. , 2.5, 5. , 2. ],\n",
       "       [0. , 2.8, 0. , 2.4],\n",
       "       [0. , 3.2, 0. , 2.3],\n",
       "       [0. , 3. , 0. , 1.8],\n",
       "       [0. , 3.8, 0. , 2.2],\n",
       "       [0. , 2.6, 0. , 2.3],\n",
       "       [0. , 2.2, 5. , 1.5],\n",
       "       [0. , 3.2, 0. , 2.3],\n",
       "       [0. , 2.8, 4.9, 2. ],\n",
       "       [0. , 2.8, 0. , 2. ],\n",
       "       [0. , 2.7, 4.9, 1.8],\n",
       "       [0. , 3.3, 0. , 2.1],\n",
       "       [0. , 3.2, 0. , 1.8],\n",
       "       [0. , 2.8, 4.8, 1.8],\n",
       "       [0. , 3. , 4.9, 1.8],\n",
       "       [0. , 2.8, 0. , 2.1],\n",
       "       [0. , 3. , 0. , 1.6],\n",
       "       [0. , 2.8, 0. , 1.9],\n",
       "       [0. , 3.8, 0. , 2. ],\n",
       "       [0. , 2.8, 0. , 2.2],\n",
       "       [0. , 2.8, 0. , 1.5],\n",
       "       [0. , 2.6, 0. , 1.4],\n",
       "       [0. , 3. , 0. , 2.3],\n",
       "       [0. , 3.4, 0. , 2.4],\n",
       "       [0. , 3.1, 0. , 1.8],\n",
       "       [0. , 3. , 4.8, 1.8],\n",
       "       [0. , 3.1, 0. , 2.1],\n",
       "       [0. , 3.1, 0. , 2.4],\n",
       "       [0. , 3.1, 0. , 2.3],\n",
       "       [0. , 2.7, 0. , 1.9],\n",
       "       [0. , 3.2, 0. , 2.3],\n",
       "       [0. , 3.3, 0. , 2.5],\n",
       "       [0. , 3. , 0. , 2.3],\n",
       "       [0. , 2.5, 5. , 1.9],\n",
       "       [0. , 3. , 0. , 2. ],\n",
       "       [0. , 3.4, 0. , 2.3],\n",
       "       [0. , 3. , 0. , 1.8]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dataset_temp_0 = np.where(np.isnan(iris_dataset_temp),0,iris_dataset_temp)\n",
    "iris_dataset_temp_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e67720",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
